# üöÄ CUDA Programming ‚Äì GPU Computing Basics

This repository contains my hands-on learning and implementation of **CUDA (Compute Unified Device Architecture)** using **NVIDIA GPUs**.  
The project focuses on understanding **GPU parallel programming**, CUDA memory management, and kernel execution through simple and clear examples.

All programs are compiled and executed on a **GPU-enabled Jupyter/Linux environment**.

---

## üß† Concepts Covered

- CUDA kernel programming using `__global__`
- Parallel execution using GPU threads
- GPU memory allocation with `cudaMalloc`
- Data transfer using `cudaMemcpy`
- Thread indexing with `threadIdx`, `blockIdx`, and `blockDim`
- Safe bounds checking in kernels
- Difference between CPU and GPU execution

---

## üìÅ Project Structure

